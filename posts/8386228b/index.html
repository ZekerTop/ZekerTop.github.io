<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Scrapy爬虫框架 | Ztop の 空间站</title><meta name="keywords" content="python爬虫之scrapy框架"><meta name="author" content="Ztop"><meta name="copyright" content="Ztop"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="python爬虫之scrapy框架">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy爬虫框架">
<meta property="og:url" content="https://www.zeker.top/posts/8386228b/index.html">
<meta property="og:site_name" content="Ztop の 空间站">
<meta property="og:description" content="python爬虫之scrapy框架">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scrapy-1.52lo4766xv40.jpg">
<meta property="article:published_time" content="2021-09-04T12:58:53.000Z">
<meta property="article:modified_time" content="2024-06-16T13:48:38.674Z">
<meta property="article:author" content="Ztop">
<meta property="article:tag" content="python">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scrapy-1.52lo4766xv40.jpg"><link rel="shortcut icon" href="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/touxiang3.4yrpzmedtq40.jpg"><link rel="canonical" href="https://www.zeker.top/posts/8386228b/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://jsd.cdn.zzko.cn/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://jsd.cdn.zzko.cn/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://jsd.cdn.zzko.cn/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://jsd.cdn.zzko.cn/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://jsd.cdn.zzko.cn/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://jsd.cdn.zzko.cn/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://jsd.cdn.zzko.cn/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Scrapy爬虫框架',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-16 21:48:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="css/background.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_3130971_tze760ab8r9.css"><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><link rel="stylesheet" href="https://jsd.cdn.zzko.cn/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async src="https://jsd.cdn.zzko.cn/npm/hexo-butterfly-tag-plugins-plus@latest/lib/carousel-touch.min.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/touxiang3.4yrpzmedtq40.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-fw fas fa-lightbulb"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw iconfont icon-room-o"></i><span> 回声间</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/artitalk/"><i class="fa-fw iconfont icon-computerRoom"></i><span> 小黑屋</span></a></li><li><a class="site-page child" href="/comments/"><i class="fa-fw iconfont icon-board"></i><span> 小黑板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 其他</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scrapy-1.52lo4766xv40.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ztop の 空间站</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-fw fas fa-lightbulb"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-user-friends"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw iconfont icon-room-o"></i><span> 回声间</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/artitalk/"><i class="fa-fw iconfont icon-computerRoom"></i><span> 小黑屋</span></a></li><li><a class="site-page child" href="/comments/"><i class="fa-fw iconfont icon-board"></i><span> 小黑板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 其他</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Scrapy爬虫框架</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-04T12:58:53.000Z" title="发表于 2021-09-04 20:58:53">2021-09-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-16T13:48:38.674Z" title="更新于 2024-06-16 21:48:38">2024-06-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/">python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/python/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Scrapy爬虫框架"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Scrapy框架概念"><a href="#Scrapy框架概念" class="headerlink" title="Scrapy框架概念"></a>Scrapy框架概念</h2><p><code>Scrapy</code>是一个Python编写的开源网络爬虫框架。它是一个被设计用于爬取网络数据、提取结构性数据的框架。</p>
<p>Scrapy文档地址：<a target="_blank" rel="noopener" href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/overview.html">http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/overview.html</a></p>
<h2 id="Scrapy框架作用"><a href="#Scrapy框架作用" class="headerlink" title="Scrapy框架作用"></a>Scrapy框架作用</h2><p>少量的代码，就能够快速的抓取。一般用于爬取大量数据。</p>
<h2 id="Scrapy框架工作流程"><a href="#Scrapy框架工作流程" class="headerlink" title="Scrapy框架工作流程"></a>Scrapy框架工作流程</h2><ol>
<li><p>回顾request的爬虫流程</p>
<p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/原始的爬虫流程.1a7d9jv58bmo.jpg" alt="原始的爬虫流程"></p>
<p>我们可以在此基础上改写流程：</p>
<p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/改写的爬虫流程.ef49avaji3k.png" alt="改写的爬虫流程"></p>
<p>而上面改写的流程图也更加便于大家去理解scrapy的流程</p>
</li>
<li><p>Scapy的流程</p>
<p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scapy的流程.2rcpyfhjjoo0.png" alt="scapy的流程"></p>
<h3 id="其流程详细如下："><a href="#其流程详细如下：" class="headerlink" title="其流程详细如下："></a>其流程详细如下：</h3><ol>
<li>爬虫中起始的url构造成request对象——&gt;爬虫中间件——&gt;引擎——&gt;调度器</li>
<li>调度器把request——&gt;引擎——&gt;下载中间件——&gt;下载器 </li>
<li>下载器发送请求，获取response响应——&gt;下载中间件——&gt;引擎——&gt;爬虫中间件——&gt;爬虫 </li>
<li>爬虫提取url地址，组装成request对象——&gt;爬虫中间件——&gt;引擎——&gt;调度器，重复步骤2 </li>
<li>爬虫提取数据——&gt;引擎——&gt;管道处理和保存数据</li>
</ol>
</li>
</ol>
<div class="note warning no-icon flat"><p>​    注意：</p>
<ul>
<li>图中绿色线条的表示数据的传递</li>
<li>注意图中中间件的位置，决定了其作用</li>
<li>注意其中引擎的位置，所有的模块之前相互独立，只和引擎进行交互</li>
</ul>
</div>
<h2 id="各模块的具体作用"><a href="#各模块的具体作用" class="headerlink" title="各模块的具体作用"></a>各模块的具体作用</h2><p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/各模块作用.5z8n2kdpqtw0.jpg" alt="各模块作用"></p>
<p>​    各模块功能：</p>
<ul>
<li>引擎 —— 数据和信号的传递</li>
<li>调度器 —— 任务url队列</li>
<li>下载器 —— 发送请求、获取响应</li>
<li>爬虫 —— 起始的url、解析数据</li>
<li>管道 —— 保存数据</li>
<li>中间件 —— 定制化操作</li>
</ul>
<h2 id="三个内置对象"><a href="#三个内置对象" class="headerlink" title="三个内置对象"></a>三个内置对象</h2><ul>
<li>request请求对象：由url、method、post_data、headers等构成 </li>
<li>response响应对象：由url、body、status、headers等构成 </li>
<li>item数据对象：本质是个字典</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>有时pip版本过于老旧不能使用，需要升级pip版本，输入<code>pip install --upgrade pip</code>回车，升级成功</p>
<p>安装scrapy命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip/pip3 install Scrapy</span><br></pre></td></tr></table></figure>
<h2 id="scrapy项目开发流程"><a href="#scrapy项目开发流程" class="headerlink" title="scrapy项目开发流程"></a>scrapy项目开发流程</h2><ol>
<li>创建项目</li>
<li>生成一个爬虫</li>
<li>提取数据</li>
<li>保存数据</li>
</ol>
<h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><p>创建scrpy项目的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;项目名字&gt;</span><br></pre></td></tr></table></figure>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject myspider</span><br></pre></td></tr></table></figure>
<h2 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h2><div class="note info flat"><p>通过命令创建出爬虫文件，爬虫文件为主要的代码作业文件，通常一个网站的爬取动作都会在爬虫文件中进行编写。</p>
</div>
<p>命令：在<strong>项目路径下</strong>执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider &lt;爬虫名字&gt; &lt;允许爬取的域名&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>爬虫名字：作为爬虫运行时的参数</li>
<li>允许爬取的域名：为对于爬虫设置的爬取范围，设置之后用于过滤要爬取的url，如果爬取的url与允许的域不通则被过滤掉。如不确定时，可以设置xx.com，后期再进行修改。</li>
</ul>
<p>这里我们以<code>豆瓣电影Top250</code>作为示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd myspider</span><br><span class="line">scrapy genspider douban movie.douban.com</span><br></pre></td></tr></table></figure>
<p>生成的目录和文件结果如下：</p>
<p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/目录文件总览.5z4b3r667x00.jpg" alt="目录文件总览"></p>
<h2 id="完善爬虫"><a href="#完善爬虫" class="headerlink" title="完善爬虫"></a>完善爬虫</h2><p>在上一步生成出来的爬虫文件中编写指定网站的数据采集操作，实现数据提取</p>
<p><strong>一、在item.py中定义要提取的字段</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    num = scrapy.Field()	<span class="comment"># 电影序号   </span></span><br><span class="line">    name = scrapy.Field()	<span class="comment"># 电影名字</span></span><br><span class="line">    score = scrapy.Field()	<span class="comment"># 电影评分   </span></span><br><span class="line">    con = scrapy.Field()	<span class="comment"># 电影简介</span></span><br></pre></td></tr></table></figure>
<p><strong>二、在/myspider/myspider/spiders/douban.py 中修改内容如下</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> MyspiderItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;douban&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;movie.douban.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://movie.douban.com/top250&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># 电影名字</span></span><br><span class="line">        name = response.xpath(<span class="string">&#x27;.//div[@id=&quot;content&quot;]/div/div/ol/li[*]/div/div/div/a/span[1]/text()&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 电影评分</span></span><br><span class="line">        score = response.xpath(<span class="string">&#x27;.//*[@id=&quot;content&quot;]/div/div[1]s/ol/li[*]/div/div/div/div/span[3]/@content&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 美化格式</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">            <span class="comment">#在爬虫中导入并且实例化对象, 使用方法跟使用字典类似</span></span><br><span class="line">            item = MyspiderItem()</span><br><span class="line">            item[<span class="string">&#x27;name&#x27;</span>] = name[i]	<span class="comment"># 这里的键名要跟item.py中字段名一致</span></span><br><span class="line">            item[<span class="string">&#x27;score&#x27;</span>] = score[i]</span><br><span class="line">            <span class="built_in">print</span>(item)</span><br><span class="line">            <span class="keyword">yield</span> item      <span class="comment"># yield 会把数据传给管道</span></span><br></pre></td></tr></table></figure>
<div class="note warning no-icon flat"><p>注意：</p>
<ul>
<li>scrapy.Spider爬虫类中必须有名为parse的解析</li>
<li>如果网站结构层次比较复杂，也可以自定义其他解析函数</li>
<li>在解析函数中提取的url地址如果要发送请求，则必须属于allowed_domains范围内，但是start_urls中的url地 址不受这个限制，我们会在后续的课程中学习如何在解析函数中构造发送请求</li>
<li>启动爬虫的时候注意启动的位置，是在项目路径下启动</li>
<li>parse()函数中使用yield返回数据，注意：解析函数中的yield能够传递的对象只能是：BaseItem, Request, dict, None</li>
</ul>
</div>
<p><strong>三、定位元素以及提取数据、属性值的方法</strong></p>
<div class="note info flat"><p>解析并获取scrapy爬虫中的数据: 利用xpath规则字符串进行定位和提取</p>
</div>
<ol>
<li><p>response.xpath方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有 一些额外的方法</p>
</li>
<li><p>额外方法extract()：返回一个包含有字符串的列表（相当于getall() ）</p>
</li>
<li><p>额外方法extract_first()：返回列表中的第一个字符串，列表为空没有返回None（相当于get() ）</p>
</li>
</ol>
<p><strong>四、response响应对象的常用属性</strong></p>
<ul>
<li>response.url：当前响应的url地址</li>
<li>response.request.url：当前响应对应的请求的url地址</li>
<li>response.headers：响应头</li>
<li>response.requests.headers：当前响应的请求头 </li>
<li>response.body：响应体，也就是html代码，byte类型</li>
<li>response.status：响应状态码</li>
</ul>
<p><strong>五、（改进版）可构造Request对象，并发送请求</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> MyspiderItem</span><br><span class="line"></span><br><span class="line">num = <span class="number">0</span>     <span class="comment"># 全局变量</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;douban&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;movie.douban.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://movie.douban.com/top250&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># 电影名字</span></span><br><span class="line">        name = response.xpath(<span class="string">&#x27;.//div[@id=&quot;content&quot;]/div/div/ol/li[*]/div/div/div/a/span[1]/text()&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 电影评分</span></span><br><span class="line">        score = response.xpath(<span class="string">&#x27;.//*[@id=&quot;content&quot;]/div/div[1]/ol/li[*]/div/div/div/div/span[2]/text()&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 电影链接</span></span><br><span class="line">        link = response.xpath(<span class="string">&#x27;.//*[@id=&quot;content&quot;]/div/div[1]/ol/li[*]/div/div[2]/div[1]/a/@href&#x27;</span>).getall()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 美化格式</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">            item = MyspiderItem()</span><br><span class="line">            <span class="keyword">global</span> num</span><br><span class="line">            <span class="keyword">if</span> num == i:        <span class="comment"># 防止乱序</span></span><br><span class="line">                item[<span class="string">&#x27;num&#x27;</span>] = num+<span class="number">1</span></span><br><span class="line">                item[<span class="string">&#x27;name&#x27;</span>] = name[i]</span><br><span class="line">                item[<span class="string">&#x27;score&#x27;</span>] = score[i]</span><br><span class="line">                <span class="comment"># print(item)</span></span><br><span class="line">                <span class="comment"># yield item      # yield 会把数据传给管道</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># print(link[i])</span></span><br><span class="line">                <span class="comment"># 对获取的电影链接去发送请求</span></span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(link[i], callback=self.parse_data, meta=&#123;<span class="string">&#x27;item2&#x27;</span>: item&#125;)</span><br><span class="line">                num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 翻页操作一</span></span><br><span class="line">        next_url = response.xpath(<span class="string">&#x27;.//*[@id=&quot;content&quot;]/div/div[1]/div[2]/span[3]/a/@href&#x27;</span>).get()</span><br><span class="line">        <span class="comment"># 拼接</span></span><br><span class="line">        next_url = <span class="string">&#x27;https://movie.douban.com/top250&#x27;</span> + next_url</span><br><span class="line"></span><br><span class="line">        <span class="comment"># # 翻页操作二</span></span><br><span class="line">        <span class="comment"># # n_url = response.xpath(&quot;//a[text()=&#x27;后页&gt;&#x27;]/@href&quot;)</span></span><br><span class="line">        <span class="comment"># # 直接使用response携带残缺的url</span></span><br><span class="line">        <span class="comment"># # yield response.follow(n_url, callback=self.parse)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 手动构造请求对象，指定解析起始url的parse方法</span></span><br><span class="line">        <span class="comment"># yield scrapy.Request(next_url, callback=self.parse)   # 数据过多，防止被反爬，先注释掉  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析详情的函数(自定义)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_data</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = response.meta.get(<span class="string">&#x27;item2&#x27;</span>)   <span class="comment"># 或 item = response.meta[&#x27;item2&#x27;]</span></span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取详情简介</span></span><br><span class="line">        <span class="comment"># 有的节点不一样，有些是div/span   有些div/span/span</span></span><br><span class="line">        <span class="comment"># // *[ @ id = &quot;link-report&quot;] / span[1] / text()</span></span><br><span class="line">        <span class="comment"># // *[ @ id = &quot;link-report&quot;] / span[1] / span / text()</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># content = response.xpath(&#x27;//*[@id=&quot;link-report&quot;]/span[1]/span/text()&#x27;).get()</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># string(path) 方法会提取父标签下的文本内容</span></span><br><span class="line">        <span class="comment"># path  就是父标签的路径</span></span><br><span class="line">        content = response.xpath(<span class="string">&#x27;string(.//*[@id=&quot;link-report&quot;]/span)&#x27;</span>).get()</span><br><span class="line">        <span class="comment"># print(&#x27;详情:&#x27;, content)</span></span><br><span class="line">        item[<span class="string">&#x27;con&#x27;</span>] = content.strip()  <span class="comment"># strip()去除左右两边的空格</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p>scrapy.Request()中的常见参数解释</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
<th>是否必填</th>
</tr>
</thead>
<tbody>
<tr>
<td>url</td>
<td>请求的url</td>
<td>是</td>
</tr>
<tr>
<td>callback</td>
<td>回调函数，用于接收请求后的返回信息，若没指定，则默认为parse()函数</td>
<td>是</td>
</tr>
<tr>
<td>meta</td>
<td>方法之间以字典形式传递参数，这个参数一般也可在<code>middlewares</code>中处理</td>
<td>否</td>
</tr>
<tr>
<td>method</td>
<td>http请求的方式，默认为GET请求，一般不需要指定。若需要POST请求，建议使用用<code>scrapy.FormRequest()</code></td>
<td>否</td>
</tr>
<tr>
<td>headers</td>
<td>dict类型，请求头信息，一般在settings中设置即可，也可在middlewares中设置</td>
<td>否</td>
</tr>
<tr>
<td>cookies</td>
<td>dict或list类型，请求的cookie</td>
<td>否</td>
</tr>
<tr>
<td>dont_filter</td>
<td>是否开启过滤，默认关闭，开启之后爬取过的url,下一次不会再爬取</td>
<td>否</td>
</tr>
<tr>
<td>errback</td>
<td>抛出错误的回调函数并打印出来，错误包括404，超时，DNS错误等</td>
<td>否</td>
</tr>
</tbody>
</table>
</div>
<div class="note success no-icon flat"><p>发送post请求</p>
<p><code>scrapy.FormRequest(url，callback, formdata)</code></p>
<p>FormRequest 类为Request的子类，用于POST请求，其他参数与Request一样，其中新增的<code>formdata</code>是dict类型，相当于meta。</p>
</div>
<h2 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h2><div class="note info flat"><p>利用管道pipeline来处理（保存）数据</p>
</div>
<p><strong>一、在pipelines.py文件中定义对数据的操作</strong></p>
<ol>
<li>定义一个管道类</li>
<li>重写管道类的process_item方法</li>
<li>process_item方法处理完item之后必须返回给引擎</li>
<li>定义数据的保存逻辑</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;douban.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment"># with open(&#x27;douban250.txt&#x27;, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) as f:</span></span><br><span class="line">        <span class="comment">#     f.write(str(item) + &#x27;\n&#x27;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 把传递数据的载体item对象转为一个字典</span></span><br><span class="line">        dic = <span class="built_in">dict</span>(item)</span><br><span class="line">        js_data = json.dumps(dic, ensure_ascii=<span class="literal">False</span>) + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">        self.file.write(js_data)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>
<ul>
<li>def open_spider(self, spider) —— 爬虫<code>开启</code>时执行一次，可用来<code>打开</code>文件</li>
<li>def process_item(self, item, spider) ——实现数据的写入操作</li>
<li>def close_spider(self, spider) —— 爬虫<code>关闭</code>时执行一次，可用来<code>关闭</code>文件</li>
</ul>
<p><strong>二、在settings.py 配置启用管道</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用管道配置</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;myspider.pipelines.MyspiderPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绕过robots规则，直接爬取页面</span></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加User-agent</span></span><br><span class="line"><span class="comment">#USER_AGENT = &#x27;myspider (+http://www.yourdomain.com)&#x27;</span></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加cookie</span></span><br><span class="line">COOKIES_ENABLED = <span class="literal">False</span></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">  <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>setting.py一般都会将<code>管道配置</code>注释掉，取消注释即可。</p>
<p>配置项中键为使用的管道类，管道类使用<code>.</code>进行分割，第一个为<code>项目目录</code>，第二个为<code>文件</code>，第三个为<code>定义的管道类</code>。 配置项中值为管道的使用顺序，设置的数值<code>越小越优先执行</code>，该值一般设置为1000以内。</p>
<h2 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h2><p>命令：在<strong>项目目录下</strong>执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl &lt;爬虫名字&gt;	(--nolog)</span><br></pre></td></tr></table></figure>
<div class="note orange icon flat"><i class="note-icon fas fa-battery-half"></i><p>—-nolog：不显示调试信息，不加即默认显示</p>
</div>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl douban --nolog</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<p><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/运行结果.5s2ykwcn5bk0.jpg" alt="运行结果" style="zoom:67%;" /></p>
<h2 id="crawlspider爬虫"><a href="#crawlspider爬虫" class="headerlink" title="crawlspider爬虫"></a>crawlspider爬虫</h2><p>回顾之前的代码，有很多一部分时间都寻找下一页的url地址或者内容的url地址上面，而这个过程能更简单吗？</p>
<p>需求思路：</p>
<ol>
<li>从response中提取所有的满足规则的url地址</li>
<li>自动的构造自己requests请求，发送给引擎</li>
</ol>
<p>而<code>crawlspider</code>就可以满足上述需求，能够匹配满足条件的url地址，组装成Reuqest对象后自动发送给引擎， 同时能够指定callback函数，</p>
<p>即：<u>crawlspider爬虫可以按照规则自动获取连接</u></p>
<div class="note info no-icon flat"><p>Scrapy框架中分两类爬虫，Spider类和CrawlSpider类。CrawlSpider继承自spider，只不过是在之前的基础上增加了新的功能。可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动yield Request。</p>
</div>
<h2 id="创建crawlspider爬虫并观察爬虫内的默认内容"><a href="#创建crawlspider爬虫并观察爬虫内的默认内容" class="headerlink" title="创建crawlspider爬虫并观察爬虫内的默认内容"></a>创建crawlspider爬虫并观察爬虫内的默认内容</h2><p><strong>一、创建crawlspider爬虫：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -t crawl douban movie.douban.com</span><br></pre></td></tr></table></figure>
<p><strong>二、spider中默认生成的内容如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubnSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;douban&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;movie.douban.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://movie.douban.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r&#x27;Items/&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = &#123;&#125;</span><br><span class="line">        <span class="comment">#item[&#x27;domain_id&#x27;] = response.xpath(&#x27;//input[@id=&quot;sid&quot;]/@value&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;name&#x27;] = response.xpath(&#x27;//div[@id=&quot;name&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="comment">#item[&#x27;description&#x27;] = response.xpath(&#x27;//div[@id=&quot;description&quot;]&#x27;).get()</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p><strong>三、观察其与跟普通的scrapy.spider的区别</strong></p>
<div class="note danger flat"><p>在crawlspider爬虫中，没有parse函数</p>
</div>
<p>重点在<code>rules</code>中： </p>
<ol>
<li>rules是一个元组或者是列表，包含的是Rule对象</li>
<li>Rule表示规则，其中包含LinkExtractor，callback和follow等参数 </li>
<li>LinkExtractor:连接提取器，可以通过<code>正则</code>或者是<code>xpath</code>来进行url地址的匹配 </li>
<li>callback :表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调函数 的处理 </li>
<li>follow：连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，True表示会，Flase表示不会</li>
</ol>
<p><strong>四、crawlspider使用的注意点</strong></p>
<ol>
<li>除了用命令 <code>scrapy genspider -t crawl &lt;爬虫名&gt;  &lt;allowed_domail&gt;</code>创建一个crawlspider的模板，页可以手动创建</li>
<li>crawlspider中<code>不能</code>再有以<code>parse</code>为名的数据提取方法，该方法被crawlspider用来实现基础url提取等功能</li>
<li>Rule对象中LinkExtractor为固定参数，其他callback、follow为可选参数</li>
<li>不指定callback且follow为True的情况下，满足rules中规则的url还会被继续提取和请求</li>
<li>如果一个被提取的url满足多个Rule，那么会从rules中选择一个满足匹配条件的Rule执行</li>
</ol>
<p><strong>五、crawlspider其他知识点的了解</strong></p>
<ol>
<li>链接提取器<code>LinkExtractor</code>的更多常见参数<ul>
<li>allow：满足括号中的’re’表达式的url会被提取，如果为空，则全部匹配 </li>
<li>deny：满足括号中的’re’表达式的url不会被提取，优先级高于allow </li>
<li>allow_domains：会被提取的链接的domains(url范围)，如： [‘hr.tencent.com’, ‘baidu.com’] </li>
<li>deny_domains：不会被提取的链接的domains(url范围) </li>
<li>restrict_xpaths：使用xpath规则进行匹配，和allow共同过滤url，即xpath满足的范围内的url地址会被 提取，如： restrict_xpaths=’//div[@class=”pagenav”]’</li>
</ul>
</li>
<li><code>Rule</code>常见参数<ul>
<li>LinkExtractor：链接提取器，可以通过正则或者是xpath来进行url地址的匹配 </li>
<li>callback：表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调 函数的处理 </li>
<li>follow：连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，默认True表示会， Flase表示不会 </li>
<li>process_links：当链接提取器LinkExtractor获取到链接列表的时候调用该参数指定的方法，这个自定义方 法可以用来过滤url，且这个方法执行后才会执行callback指定的方法</li>
</ul>
</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Ztop</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.zeker.top/posts/8386228b/">https://www.zeker.top/posts/8386228b/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.zeker.top" target="_blank">Ztop の 空间站</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scrapy-1.52lo4766xv40.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://jsd.cdn.zzko.cn/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://jsd.cdn.zzko.cn/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://unpkg.zhimg.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/6cb57fa2/"><img class="prev-cover" src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210809/redi3-3.6h3pj74p2b80.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Redis学习笔记（3）</div></div></a></div><div class="next-post pull-right"><a href="/posts/510672c5/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/ZekerTop/images@main/20220110/webshell1.110bz2j3f3xc.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">WebShell（1）| 基础详解</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/7ee00516/" title="针对eduSrc平台制作搜索脚本"><img class="cover" src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20220208/wallhaven-83153y.1411bt8maduo.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-06</div><div class="title">针对eduSrc平台制作搜索脚本</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/touxiang3.4yrpzmedtq40.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ztop</div><div class="author-info__description">去更远的地方，见更亮的光</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZekerTop"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZekerTop" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:top.zeker@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1503675793&amp;site=qq&amp;menu=yes" target="_blank" title="qq"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">学习路上永不止境！！！<img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/my_bg.74vya3aoiik0.gif"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy%E6%A1%86%E6%9E%B6%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">Scrapy框架概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy%E6%A1%86%E6%9E%B6%E4%BD%9C%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">Scrapy框架作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy%E6%A1%86%E6%9E%B6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">Scrapy框架工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E6%B5%81%E7%A8%8B%E8%AF%A6%E7%BB%86%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">其流程详细如下：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E6%A8%A1%E5%9D%97%E7%9A%84%E5%85%B7%E4%BD%93%E4%BD%9C%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">各模块的具体作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E5%86%85%E7%BD%AE%E5%AF%B9%E8%B1%A1"><span class="toc-number">5.</span> <span class="toc-text">三个内置对象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">6.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="toc-number">7.</span> <span class="toc-text">scrapy项目开发流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">8.</span> <span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB"><span class="toc-number">9.</span> <span class="toc-text">创建爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E5%96%84%E7%88%AC%E8%99%AB"><span class="toc-number">10.</span> <span class="toc-text">完善爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE"><span class="toc-number">11.</span> <span class="toc-text">保存数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%88%AC%E8%99%AB"><span class="toc-number">12.</span> <span class="toc-text">运行爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#crawlspider%E7%88%AC%E8%99%AB"><span class="toc-number">13.</span> <span class="toc-text">crawlspider爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAcrawlspider%E7%88%AC%E8%99%AB%E5%B9%B6%E8%A7%82%E5%AF%9F%E7%88%AC%E8%99%AB%E5%86%85%E7%9A%84%E9%BB%98%E8%AE%A4%E5%86%85%E5%AE%B9"><span class="toc-number">14.</span> <span class="toc-text">创建crawlspider爬虫并观察爬虫内的默认内容</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/gptplus-sui-xin-yong/" title="GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/gptplus-sui-xin-yong.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式"/></a><div class="content"><a class="title" href="/posts/gptplus-sui-xin-yong/" title="GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式">GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式</a><time datetime="2024-05-12T01:23:44.000Z" title="发表于 2024-05-12 09:23:44">2024-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/chatgpt4-mirror-site/" title="ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/images2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧"/></a><div class="content"><a class="title" href="/posts/chatgpt4-mirror-site/" title="ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧">ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧</a><time datetime="2024-04-18T14:10:07.000Z" title="发表于 2024-04-18 22:10:07">2024-04-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/how-to-upgrade-chatgpt/" title="ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/how-to-upgrade-chatgpt.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）"/></a><div class="content"><a class="title" href="/posts/how-to-upgrade-chatgpt/" title="ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）">ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）</a><time datetime="2024-04-13T09:15:56.000Z" title="发表于 2024-04-13 17:15:56">2024-04-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/how_to_subscribe_to_onlyfans/" title="如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/17.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）"/></a><div class="content"><a class="title" href="/posts/how_to_subscribe_to_onlyfans/" title="如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）">如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）</a><time datetime="2024-04-13T06:37:08.000Z" title="发表于 2024-04-13 14:37:08">2024-04-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/chapter4-upgrade-precautions/" title="升级ChatGPT4.0，原来还需要注意这些？"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240311/2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="升级ChatGPT4.0，原来还需要注意这些？"/></a><div class="content"><a class="title" href="/posts/chapter4-upgrade-precautions/" title="升级ChatGPT4.0，原来还需要注意这些？">升级ChatGPT4.0，原来还需要注意这些？</a><time datetime="2024-03-11T14:50:18.000Z" title="发表于 2024-03-11 22:50:18">2024-03-11</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20210906/scrapy-1.52lo4766xv40.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2024 <i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;" class="fa fa-heartbeat"></i> Ztop</div><div id="workboard"></div><script async="async" src="/js/runtime.js"></script><div class="footer_custom_text"><p> <a style="margin-inline:5px"target="_blank" href="https://hexo.io/"> <img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为 Hexo" alt="HEXO"></a> <a style="margin-inline:5px"target="_blank" href="https://butterfly.js.org/"> <img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用 Butterfly" alt="Butterfly"></a> <a style="margin-inline:5px"target="_blank" href="https://www.jsdelivr.com/"> <img src="https://img.shields.io/badge/CDN-jsDelivr-green?style=flat&logo=jsDelivr" title="本站使用 JsDelivr 为静态资源提供CDN加速" alt="JsDelivr"></a> <a style="margin-inline:5px"target="_blank" href="https://twikoo.js.org/"> <img src="https://img.shields.io/badge/Comment-Twikoo-orange?style=flat&logo=Vercel" title="Twikoo 提供评论支持" alt="Twikoo"></a> <a style="margin-inline:5px"target="_blank" href="https://github.com/"> <img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由 GitHub 托管" alt="GitHub"></a> <a style="margin-inline:5px"target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"> <img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" alt="BY--NC--SA4.0"></a> <br> <img src="https://s1.ax1x.com/2018/09/29/ilmwIH.png"> <a href="https://beian.miit.gov.cn"  style="color:#f0d784" target="_blank">粤ICP备2021107291号-1</a> </p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://jsd.cdn.zzko.cn/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://jsd.cdn.zzko.cn/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://jsd.cdn.zzko.cn/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-ten-red.vercel.app/',
      region: ''
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo-ten-red.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://jsd.cdn.zzko.cn/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo-ten-red.vercel.app/',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://jsd.cdn.zzko.cn/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><div class="aplayer no-destroy" data-id="6751453557" data-server="tencent" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="false" muted></div><script async src="//at.alicdn.com/t/font_2264842_3izu8i5eoc2.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://jsd.cdn.zzko.cn/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://jsd.cdn.zzko.cn/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://jsd.cdn.zzko.cn/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://jsd.cdn.zzko.cn/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://jsd.cdn.zzko.cn/npm/aplayer/dist/APlayer.min.js"></script><script src="https://jsd.cdn.zzko.cn/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://jsd.cdn.zzko.cn/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/gptplus-sui-xin-yong.png" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/gptplus-sui-xin-yong.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-05-12</span><a class="blog-slider__title" href="posts/gptplus-sui-xin-yong/">GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式</a><div class="blog-slider__text">GPTplus(GPT4)随心用，更低的价格，账户共享但独立的全新使用方式</div><a class="blog-slider__button" href="posts/gptplus-sui-xin-yong/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/images2.png" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/images2.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-04-18</span><a class="blog-slider__title" href="posts/chatgpt4-mirror-site/">ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧</a><div class="blog-slider__text">ChatGPT4.0账号被封了怎么办？先试试这个镜像站吧</div><a class="blog-slider__button" href="posts/chatgpt4-mirror-site/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240303/twikoo-2.jpg" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240303/twikoo-2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-03-03</span><a class="blog-slider__title" href="posts/upgrade-chatgpt-to-plus/">开启AI赚钱之旅！5分钟教你怎么注册并升级ChatGPT Plus【详细GPT注册升级流程】</a><div class="blog-slider__text">开启AI赚钱之旅！5分钟教你怎么注册并升级ChatGPT Plus【详细GPT注册升级流程】</div><a class="blog-slider__button" href="posts/upgrade-chatgpt-to-plus/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/how-to-upgrade-chatgpt.jpg" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240512/how-to-upgrade-chatgpt.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-04-13</span><a class="blog-slider__title" href="posts/how-to-upgrade-chatgpt/">ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）</a><div class="blog-slider__text">ChatGPT Plus 如何购买？GPT4 如何升级（2024 GPT4、GPT4.0升级最新详细教学）</div><a class="blog-slider__button" href="posts/how-to-upgrade-chatgpt/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/17.png" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240413/17.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-04-13</span><a class="blog-slider__title" href="posts/how_to_subscribe_to_onlyfans/">如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）</a><div class="blog-slider__text">如何订阅 OnlyFans？OnlyFans 虚拟卡订阅教程（2024 最新保姆级 超详细）</div><a class="blog-slider__button" href="posts/how_to_subscribe_to_onlyfans/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240311/2.jpg" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240311/2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-03-11</span><a class="blog-slider__title" href="posts/chapter4-upgrade-precautions/">升级ChatGPT4.0，原来还需要注意这些？</a><div class="blog-slider__text">后悔没有早点看到这个了！！</div><a class="blog-slider__button" href="posts/chapter4-upgrade-precautions/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240303/twikoo-1.jpg" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20240303/twikoo-1.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-03-03</span><a class="blog-slider__title" href="posts/buy-chatgpt-account/">国内ChatGPT账号免费注册教程，无需手机验证码【2024年最新教程】</a><div class="blog-slider__text">国内ChatGPT账号免费注册教程，无需手机验证码【2024年最新教程】</div><a class="blog-slider__button" href="posts/buy-chatgpt-account/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20220208/wallhaven-83153y.1411bt8maduo.jpg" alt="https://jsd.cdn.zzko.cn/gh/ZekerTop/images@main/20220208/wallhaven-83153y.1411bt8maduo.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2022-02-06</span><a class="blog-slider__title" href="posts/7ee00516/">针对eduSrc平台制作搜索脚本</a><div class="blog-slider__text">eduSrc平台搜索脚本</div><a class="blog-slider__button" href="posts/7ee00516/">详情</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载swiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>